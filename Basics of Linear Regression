import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score

# サンプルデータ (Sample Data)
data_x = np.array([1, 2, 3, 4, 5])
data_y = np.array([2, 4, 5, 4, 5])

# 平均 (Mean)
mean_x = np.mean(data_x)
mean_y = np.mean(data_y)

# 最大値・最小値 (Max and Min)
max_x = np.max(data_x)
min_x = np.min(data_x)

# 最頻値 (Mode)
mode_x = stats.mode(data_x)
mode_y = stats.mode(data_y)

# 中央値 (Median)
median_x = np.median(data_x)
median_y = np.median(data_y)

# 四分位数 (Quartiles)
quartiles_x = np.percentile(data_x, [25, 50, 75])

# 分散・標準偏差 (Variance and Standard Deviation)
variance_x = np.var(data_x)
std_dev_x = np.std(data_x)

# 共分散 (Covariance)
covariance = np.cov(data_x, data_y)[0, 1]

# 相関係数 (Correlation Coefficient)
correlation = np.corrcoef(data_x, data_y)[0, 1]

# 線形回帰と決定係数 (Linear Regression and R-squared)
X = data_x.reshape(-1, 1)  # データを適切な形状に変換
model = LinearRegression().fit(X, data_y)  # 線形回帰モデルをフィット
y_pred = model.predict(X)  # 予測値
r_squared = r2_score(data_y, y_pred)  # 決定係数

# 回帰平方和・総平方和 (Sums of Squares)
regression_sum_of_squares = np.sum((y_pred - np.mean(data_y)) ** 2)
total_sum_of_squares = np.sum((data_y - np.mean(data_y)) ** 2)

# プロット (Plot)
plt.scatter(data_x, data_y, color='blue', label='Data')  # データの散布図
plt.plot(data_x, y_pred, color='red', label='Linear Fit')  # 回帰直線
plt.title('Linear Regression and Data')  # グラフのタイトル
plt.xlabel('X-axis')  # X軸ラベル
plt.ylabel('Y-axis')  # Y軸ラベル
plt.legend()  # 凡例
plt.show()  # グラフを表示

# 結果表示 (Results)
print(f"Mean of X: {mean_x}, Mean of Y: {mean_y}")  # 平均
print(f"Max of X: {max_x}, Min of X: {min_x}")  # 最大値・最小値
print(f"Mode of X: {mode_x.mode[0]}, Mode of Y: {mode_y.mode[0]}")  # 最頻値
print(f"Median of X: {median_x}, Median of Y: {median_y}")  # 中央値
print(f"Quartiles of X: {quartiles_x}")  # 四分位数
print(f"Variance of X: {variance_x}, Std Dev of X: {std_dev_x}")  # 分散、標準偏差
print(f"Covariance: {covariance}")  # 共分散
print(f"Correlation Coefficient: {correlation}")  # 相関係数
print(f"R-squared: {r_squared}")  # 決定係数
print(f"Regression Sum of Squares: {regression_sum_of_squares}")  # 回帰平方和
print(f"Total Sum of Squares: {total_sum_of_squares}")  # 総平方和
